{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3EVILI8zfgd"
      },
      "source": [
        "# Creating embedding using gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLbMBQyezbo1",
        "outputId": "731f1022-d58d-4b6a-8692-f00913572f68"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 93 kB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PcVwF-hIJ9h",
        "outputId": "684c2a63-8285-44a5-db52-bb641f1fac12"
      },
      "source": [
        "!git clone https://github.com/hgrif/wiki-word2vec.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'wiki-word2vec'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Total 42 (delta 0), reused 0 (delta 0), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goSX-OaZIvd4",
        "outputId": "efcd47f9-48f3-4c32-fb43-0f6635110067"
      },
      "source": [
        "#Get swahili data\n",
        "!mkdir -p data/sw/\n",
        "!wget -P data/sw/ https://dumps.wikimedia.org/swwiki/latest/swwiki-latest-pages-articles.xml.bz2\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-24 10:35:07--  https://dumps.wikimedia.org/swwiki/latest/swwiki-latest-pages-articles.xml.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34806466 (33M) [application/octet-stream]\n",
            "Saving to: ‘data/sw/swwiki-latest-pages-articles.xml.bz2’\n",
            "\n",
            "swwiki-latest-pages 100%[===================>]  33.19M  4.23MB/s    in 7.6s    \n",
            "\n",
            "2021-08-24 10:35:15 (4.36 MB/s) - ‘data/sw/swwiki-latest-pages-articles.xml.bz2’ saved [34806466/34806466]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImV9Ip36tFZ9",
        "outputId": "a2c1f984-a4a2-4f93-ab7e-32f28cc7039b"
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M1mMY_iI1Vw"
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "wiki = WikiCorpus('data/sw/swwiki-latest-pages-articles.xml.bz2', \n",
        "                   dictionary={})\n",
        "sentences = list(wiki.get_texts())\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK2uzqXlI3wI"
      },
      "source": [
        "params = {'window': 10, 'min_count': 10, \n",
        "          'workers': max(1, multiprocessing.cpu_count() - 1), 'sample': 1E-3,}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQm_yn6X_PQY"
      },
      "source": [
        "word2vec = Word2Vec(sentences, **params, epochs =1)\n",
        "word2vec.save(\"word2vec.model\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL1evBAVtbun"
      },
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aqAJuXfCT2g",
        "outputId": "187ddf69-f12d-4db2-81e9-366f3418128f"
      },
      "source": [
        "vector_man = word2vec.wv['mwanaume']  # get numpy vector of a word\n",
        "\n",
        "vector_boy = word2vec.wv['mvulana']  # get numpy vector of a word\n",
        "print(\"Cosine similarity between boy and man in \"+ str(1) +\" epochs, is: \" + str(1 - cosine(vector_man, vector_boy)))\n",
        "\n",
        "vector_woman = word2vec.wv['mwanamke']  # get numpy vector of a word\n",
        "\n",
        "vector_queen = word2vec.wv['malkia']  # get numpy vector of a word\n",
        "print(\"Cosine similarity between woman and queen in \"+ str(1) +\" epochs, is: \" + str(1 - cosine(vector_woman, vector_queen)))\n",
        "\n",
        "print(\"Most 10 similar words to man\")\n",
        "sims = word2vec.wv.most_similar('mwanaume', topn=10)  # get other similar words\n",
        "print(sims)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between boy and man in 1 epochs, is: 0.8737907409667969\n",
            "Cosine similarity between woman and queen in 1 epochs, is: 0.6921840310096741\n",
            "Most 10 similar words to man\n",
            "[('aje', 0.8981823921203613), ('kumwambia', 0.8881581425666809), ('mohinder', 0.8873194456100464), ('yustus', 0.8758364915847778), ('mvulana', 0.8737908005714417), ('niko', 0.8714087605476379), ('mwenzie', 0.870768129825592), ('anazidi', 0.870003879070282), ('anampenda', 0.869492769241333), ('alipenda', 0.868550181388855)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1INGLiFQwkoR",
        "outputId": "ee2bfc40-34b5-41f6-972f-7047cf130df3"
      },
      "source": [
        "for i in range(4):  \n",
        "  word2vec.train(sentences, total_examples=word2vec.corpus_count, epochs=1)\n",
        "  vector_man = word2vec.wv['mwanaume']  # get numpy vector of a word\n",
        "  vector_boy = word2vec.wv['mvulana']  # get numpy vector of a word\n",
        "\n",
        "  print(\"Cosine similarity between boy and man in \"+ str(i+2) +\" epochs, is: \" + str(1 - cosine(vector_man, vector_boy)))\n",
        "\n",
        "  vector_woman = word2vec.wv['mwanamke']  # get numpy vector of a word\n",
        "\n",
        "  vector_queen = word2vec.wv['malkia']  # get numpy vector of a word\n",
        "  print(\"Cosine similarity between woman and queen in \"+ str(i+2) +\" epochs, is: \" + str(1 - cosine(vector_woman, vector_queen)))\n",
        "\n",
        "  print(\"Most 10 similar words to man\")\n",
        "  sims = word2vec.wv.most_similar('mwanaume', topn=10)  # get other similar words\n",
        "  print(sims)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between boy and man in 2 epochs, is: 0.7506097555160522\n",
            "Cosine similarity between woman and queen in 2 epochs, is: 0.4878472089767456\n",
            "Most 10 similar words to man\n",
            "[('mahaba', 0.8240833878517151), ('anaona', 0.8000137805938721), ('nae', 0.7809977531433105), ('mwanamume', 0.7683743238449097), ('mwenzi', 0.7664150595664978), ('uchumba', 0.7661716938018799), ('atakuwa', 0.7606471180915833), ('anaonekana', 0.7572895884513855), ('msichana', 0.7555936574935913), ('msela', 0.7535034418106079)]\n",
            "Cosine similarity between boy and man in 3 epochs, is: 0.6831587553024292\n",
            "Cosine similarity between woman and queen in 3 epochs, is: 0.4275827407836914\n",
            "Most 10 similar words to man\n",
            "[('anaona', 0.7696461081504822), ('mahaba', 0.7653655409812927), ('msela', 0.7226854562759399), ('anaanza', 0.7118600606918335), ('aliye', 0.7118346095085144), ('mwenzi', 0.6991514563560486), ('anaonekana', 0.696577250957489), ('nae', 0.6944088339805603), ('atakuwa', 0.68865567445755), ('msichana', 0.688647449016571)]\n",
            "Cosine similarity between boy and man in 4 epochs, is: 0.6312413215637207\n",
            "Cosine similarity between woman and queen in 4 epochs, is: 0.3863149583339691\n",
            "Most 10 similar words to man\n",
            "[('anaona', 0.7223778367042542), ('mahaba', 0.7179660201072693), ('anaanza', 0.7149278521537781), ('aliye', 0.6779439449310303), ('asiye', 0.6688137650489807), ('mwenzi', 0.6534646153450012), ('msichana', 0.6532779335975647), ('anaonekana', 0.6481207609176636), ('nae', 0.641811192035675), ('mwanamama', 0.6368979215621948)]\n",
            "Cosine similarity between boy and man in 5 epochs, is: 0.602271318435669\n",
            "Cosine similarity between woman and queen in 5 epochs, is: 0.33457788825035095\n",
            "Most 10 similar words to man\n",
            "[('anaona', 0.7271645665168762), ('anaanza', 0.6929378509521484), ('aliye', 0.6871325373649597), ('mahaba', 0.6783033609390259), ('asiye', 0.6641153693199158), ('anapokuwa', 0.6548054814338684), ('anaonekana', 0.652777910232544), ('mwanamume', 0.6524567604064941), ('msichana', 0.6434168815612793), ('anayeitwa', 0.6326570510864258)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmIZvHJU8u9X",
        "outputId": "54f1b778-03ba-43ec-df31-1468003dd0ea"
      },
      "source": [
        "for i in range(5, 10):  \n",
        "  word2vec.train(sentences, total_examples=word2vec.corpus_count, epochs=5)\n",
        "  vector_man = word2vec.wv['mwanaume']  # get numpy vector of a word\n",
        "  vector_boy = word2vec.wv['mvulana']  # get numpy vector of a word\n",
        "\n",
        "  print(\"Cosine similarity between boy and man in \"+ str(5 + i*5) +\" epochs, is: \" + str(1 - cosine(vector_man, vector_boy)))\n",
        "\n",
        "  vector_woman = word2vec.wv['mwanamke']  # get numpy vector of a word\n",
        "\n",
        "  vector_queen = word2vec.wv['malkia']  # get numpy vector of a word\n",
        "  print(\"Cosine similarity between woman and queen in \"+ str(5 + i*5) +\" epochs, is: \" + str(1 - cosine(vector_woman, vector_queen)))\n",
        "\n",
        "  print(\"Most 10 similar words to man\")\n",
        "  sims = word2vec.wv.most_similar('mwanaume', topn=10)  # get other similar words\n",
        "  print(sims)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between boy and man in 30 epochs, is: 0.5796116590499878\n",
            "Cosine similarity between woman and queen in 30 epochs, is: 0.3289449214935303\n",
            "Most 10 similar words to man\n",
            "[('mwanamume', 0.619727373123169), ('anaona', 0.6174345016479492), ('mahaba', 0.6098613739013672), ('asiye', 0.6018980741500854), ('anayeitwa', 0.6004301905632019), ('aliye', 0.5986660718917847), ('msichana', 0.5888607501983643), ('yule', 0.582199215888977), ('mvulana', 0.5796117782592773), ('zopa', 0.5671093463897705)]\n",
            "Cosine similarity between boy and man in 35 epochs, is: 0.5513689517974854\n",
            "Cosine similarity between woman and queen in 35 epochs, is: 0.31930071115493774\n",
            "Most 10 similar words to man\n",
            "[('mwanamume', 0.5920594334602356), ('mahaba', 0.589745044708252), ('anaona', 0.5841481685638428), ('anayeitwa', 0.5664746165275574), ('yule', 0.5593873858451843), ('msichana', 0.5557315945625305), ('mvulana', 0.5513689517974854), ('aliye', 0.5466966032981873), ('yupo', 0.5394044518470764), ('shoga', 0.5323488712310791)]\n",
            "Cosine similarity between boy and man in 40 epochs, is: 0.5025891065597534\n",
            "Cosine similarity between woman and queen in 40 epochs, is: 0.32749688625335693\n",
            "Most 10 similar words to man\n",
            "[('mwanamume', 0.5544734001159668), ('mahaba', 0.5459815263748169), ('yule', 0.5314964056015015), ('anayeitwa', 0.5233631134033203), ('anaona', 0.5197409391403198), ('msichana', 0.5153796076774597), ('shoga', 0.5132531523704529), ('aliye', 0.5091280937194824), ('yupo', 0.5080736875534058), ('mwanamke', 0.5059763193130493)]\n",
            "Cosine similarity between boy and man in 45 epochs, is: 0.4834613800048828\n",
            "Cosine similarity between woman and queen in 45 epochs, is: 0.338216632604599\n",
            "Most 10 similar words to man\n",
            "[('mahaba', 0.5408825874328613), ('mwanamume', 0.5231321454048157), ('msichana', 0.5205199122428894), ('aliye', 0.5138879418373108), ('yule', 0.509274959564209), ('mwanamke', 0.5046313405036926), ('mpenda', 0.5039784908294678), ('anaona', 0.4990381598472595), ('shoga', 0.4962906241416931), ('anayeitwa', 0.4946228563785553)]\n",
            "Cosine similarity between boy and man in 50 epochs, is: 0.4878561198711395\n",
            "Cosine similarity between woman and queen in 50 epochs, is: 0.366167813539505\n",
            "Most 10 similar words to man\n",
            "[('mwanamke', 0.5431877970695496), ('msichana', 0.5248925089836121), ('mwanamume', 0.5227726101875305), ('aliye', 0.5135815739631653), ('wachumba', 0.5093268752098083), ('mahaba', 0.5006556510925293), ('mpenda', 0.4995371103286743), ('mvulana', 0.4878561198711395), ('yupo', 0.4786035716533661), ('anayeitwa', 0.47712546586990356)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEP6crYBJ4-a"
      },
      "source": [
        "word2vec.save(\"word2vec.model\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx0x48OEJ4-b"
      },
      "source": [
        "model_swahili = Word2Vec.load(\"word2vec.model\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnFUM-cTJ4-b"
      },
      "source": [
        "vector_man = model_swahili.wv['mwanaume']  # get numpy vector of a word\n",
        "sims = model_swahili.wv.most_similar('mwanaume', topn=10)  # get other similar words"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTeqj0FWIDra",
        "outputId": "d7643cea-6906-4ec9-c0c6-e4709aae9048"
      },
      "source": [
        "sims"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mvulana', 0.7277518510818481),\n",
              " ('msichana', 0.7257815599441528),\n",
              " ('nae', 0.7235980033874512),\n",
              " ('bennet', 0.7187550067901611),\n",
              " ('nusura', 0.7069060802459717),\n",
              " ('dully', 0.6989878416061401),\n",
              " ('wakina', 0.6972491145133972),\n",
              " ('bi', 0.6946593523025513),\n",
              " ('mahaba', 0.6930020451545715),\n",
              " ('aje', 0.6900444626808167)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnJb6de2IJ4U"
      },
      "source": [
        "vector_boy = model_swahili.wv['mvulana']  # get numpy vector of a word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T6Lx-9WKBbY",
        "outputId": "36c32355-b944-40d2-ace6-e36943d9778b"
      },
      "source": [
        "1 - cosine(vector_man, vector_boy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7277519106864929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN-E-2ojIS--"
      },
      "source": [
        "vector_queen = model_swahili.wv['malkia']  # get numpy vector of a word\n",
        "sims = model_swahili.wv.most_similar('malkia', topn=10)  # get other similar words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaTs3jdMITcx",
        "outputId": "249df986-d0ed-421d-dfa7-4cc5e9b651b6"
      },
      "source": [
        "sims"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mfalme', 0.8444384932518005),\n",
              " ('mtawala', 0.7251664996147156),\n",
              " ('mkabaila', 0.6911629438400269),\n",
              " ('farao', 0.6742110252380371),\n",
              " ('mtemi', 0.6704172492027283),\n",
              " ('mrithi', 0.6614590883255005),\n",
              " ('alirithi', 0.6611064672470093),\n",
              " ('kifalme', 0.6572237610816956),\n",
              " ('alitawala', 0.6564803719520569),\n",
              " ('mke', 0.6315830945968628)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWM_1zCITha"
      },
      "source": [
        "#mfalme -> king\n",
        "#mtawala -> ruler\n",
        "#mkabaila -> landlord\n",
        "#farao -> pharaoh\n",
        "#mtemi -> spit\n",
        "#mrithi -> heir\n",
        "#alirithi -> he does not inherit\n",
        "#kifalme -> royal\n",
        "#alitawala -> he ruled\n",
        "#mke -> wife"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltjjW1qNITjy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZFju4o4bIM9"
      },
      "source": [
        "# Creating a Keras model from embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atdUjlt4KK8g"
      },
      "source": [
        "l = len(list(model_swahili.wv.index_to_key))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGZ6nHDXLkJ6"
      },
      "source": [
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence, text\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, MaxPooling1D, GlobalAveragePooling1D"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtFWNV_cTJk8"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhLQPia6TOzm"
      },
      "source": [
        "all_words = list(model_swahili.wv.index_to_key)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WXnwycuQAKi"
      },
      "source": [
        "vocab = model_swahili.wv.index_to_key    \n",
        "t = Tokenizer()\n",
        "\n",
        "vocab_size = len(all_words) + 1\n",
        "t.fit_on_texts(all_words)\n",
        "\n",
        "def get_weight_matrix():\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, model_swahili.vector_size))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for i in range(len(all_words)):\n",
        "        weight_matrix[i + 1] = model_swahili.wv[all_words[i]]\n",
        "    return weight_matrix\n",
        "\n",
        "embedding_vectors = get_weight_matrix()\n",
        "emb_layer = Embedding(vocab_size, output_dim=model_swahili.vector_size, weights=[embedding_vectors], trainable=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S2Fihh1R8sB",
        "outputId": "8f90ab3e-80ef-4374-ed13-5b43a67eff33"
      },
      "source": [
        "emb_layer"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f113e8b6e90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AThd-G-yTszy"
      },
      "source": [
        "# Create model instance\n",
        "model = models.Sequential()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLBVKgi_T7Ta"
      },
      "source": [
        "model.add(emb_layer)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arz3QzXtT8X5",
        "outputId": "961d885f-d3e2-4856-94e7-dcc27966bee4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         3834400   \n",
            "=================================================================\n",
            "Total params: 3,834,400\n",
            "Trainable params: 0\n",
            "Non-trainable params: 3,834,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pbygtJQUKV6",
        "outputId": "b9f6c7be-0a0b-4442-8e15-9413413c11b9"
      },
      "source": [
        "t.texts_to_sequences([\"mwanaume\"])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4994]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc6r5q9h8xc0"
      },
      "source": [
        "Checking similarity between keras model and the real model embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s53ymWGXT-fx"
      },
      "source": [
        "vector_man = model(t.texts_to_sequences([\"mwanaume\"]))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMBVzia7bVWQ",
        "outputId": "6acef602-f0e4-421f-f547-5c2543e3c492"
      },
      "source": [
        "vector_man"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
              "array([-3.0172608 , -1.5864413 , -1.4447039 , -0.14817056, -0.02159376,\n",
              "       -2.7592428 ,  0.71549946, -1.5223407 , -1.1996162 ,  2.046477  ,\n",
              "       -1.1711432 , -1.2182232 , -2.232007  , -0.25378558, -0.8981542 ,\n",
              "        0.585518  ,  0.22908595, -2.8375628 ,  1.0793303 ,  1.7231343 ,\n",
              "        0.11506318,  1.6207782 ,  1.112322  ,  0.31028506,  0.98109245,\n",
              "        0.14098765,  0.9957303 , -0.60776424, -2.9587255 , -0.7362973 ,\n",
              "        2.164359  ,  0.7275612 , -1.6150517 ,  1.9877877 , -1.5568479 ,\n",
              "        2.7859802 , -1.9994256 , -0.54866195,  0.01171932, -0.6619937 ,\n",
              "        2.1711128 ,  1.0920217 , -1.2081722 ,  0.19694555, -0.3982888 ,\n",
              "        0.42264226, -0.16007124,  3.2177942 , -0.3301792 ,  1.2515919 ,\n",
              "       -0.251235  , -3.4790795 , -1.4575737 , -0.6303651 ,  2.8331814 ,\n",
              "        0.237851  ,  0.99203706,  1.102811  , -0.91195667, -2.6602073 ,\n",
              "       -2.3903718 , -1.655804  , -2.7919054 , -1.315015  , -1.0214618 ,\n",
              "        0.28892642,  1.7666311 ,  1.3728402 , -2.0674553 , -1.4391924 ,\n",
              "       -2.516827  ,  0.13883445,  4.044183  ,  0.12861857,  0.9719162 ,\n",
              "       -0.73912686,  0.20364477, -0.5439616 ,  1.2045444 , -0.12987785,\n",
              "       -1.1555614 , -0.91269314,  1.6024451 , -0.37429693, -1.0396523 ,\n",
              "       -1.8381822 ,  1.2781616 , -0.5939431 , -1.8317602 , -0.3181493 ,\n",
              "        1.9558886 ,  3.3041866 ,  0.77297354, -1.2804952 , -1.0760782 ,\n",
              "       -0.59505206,  0.7473949 , -0.42239422,  1.2933376 , -0.20171005],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJFDNtpr8wWf",
        "outputId": "6811a259-828f-4fc8-df97-3240a4fa86ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_swahili.wv['mwanaume']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.0172608 , -1.5864413 , -1.4447039 , -0.14817056, -0.02159376,\n",
              "       -2.7592428 ,  0.71549946, -1.5223407 , -1.1996162 ,  2.046477  ,\n",
              "       -1.1711432 , -1.2182232 , -2.232007  , -0.25378558, -0.8981542 ,\n",
              "        0.585518  ,  0.22908595, -2.8375628 ,  1.0793303 ,  1.7231343 ,\n",
              "        0.11506318,  1.6207782 ,  1.112322  ,  0.31028506,  0.98109245,\n",
              "        0.14098765,  0.9957303 , -0.60776424, -2.9587255 , -0.7362973 ,\n",
              "        2.164359  ,  0.7275612 , -1.6150517 ,  1.9877877 , -1.5568479 ,\n",
              "        2.7859802 , -1.9994256 , -0.54866195,  0.01171932, -0.6619937 ,\n",
              "        2.1711128 ,  1.0920217 , -1.2081722 ,  0.19694555, -0.3982888 ,\n",
              "        0.42264226, -0.16007124,  3.2177942 , -0.3301792 ,  1.2515919 ,\n",
              "       -0.251235  , -3.4790795 , -1.4575737 , -0.6303651 ,  2.8331814 ,\n",
              "        0.237851  ,  0.99203706,  1.102811  , -0.91195667, -2.6602073 ,\n",
              "       -2.3903718 , -1.655804  , -2.7919054 , -1.315015  , -1.0214618 ,\n",
              "        0.28892642,  1.7666311 ,  1.3728402 , -2.0674553 , -1.4391924 ,\n",
              "       -2.516827  ,  0.13883445,  4.044183  ,  0.12861857,  0.9719162 ,\n",
              "       -0.73912686,  0.20364477, -0.5439616 ,  1.2045444 , -0.12987785,\n",
              "       -1.1555614 , -0.91269314,  1.6024451 , -0.37429693, -1.0396523 ,\n",
              "       -1.8381822 ,  1.2781616 , -0.5939431 , -1.8317602 , -0.3181493 ,\n",
              "        1.9558886 ,  3.3041866 ,  0.77297354, -1.2804952 , -1.0760782 ,\n",
              "       -0.59505206,  0.7473949 , -0.42239422,  1.2933376 , -0.20171005],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqtXujLzba7u",
        "outputId": "5f7fef2b-d872-468a-83f0-0b86a8a84c7e"
      },
      "source": [
        "tf.keras.models.save_model(\n",
        "    model, \"./model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2y3MAWjc3Vf",
        "outputId": "33421c80-4315-435e-ca3c-dbf5c11c8b3c"
      },
      "source": [
        "!tar -czvf swahili_word2vec.tar.gz -C model ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./keras_metadata.pb\n",
            "./assets/\n",
            "./variables/\n",
            "./variables/variables.index\n",
            "./variables/variables.data-00000-of-00001\n",
            "./saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb6a2g00c6jP"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(t, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc6339dG88y_"
      },
      "source": [
        "Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXmYs-QfwXs"
      },
      "source": [
        "# loading\n",
        "with open('tokenizer.pkl', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIkV0QG0f4JK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8294c6-887c-4c77-9cf8-d0f45379138b"
      },
      "source": [
        "!curl https://gsoc-tf.web.app/swahili_word2vec.tar.gz -o swahili.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13.4M  100 13.4M    0     0  5187k      0  0:00:02  0:00:02 --:--:-- 5185k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XPhxITaekB",
        "outputId": "7bafa37e-3320-4c3e-f01b-dc7fd5b15db6"
      },
      "source": [
        "!tar -xzvf swahili.tar.gz -C model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./keras_metadata.pb\n",
            "./assets/\n",
            "./variables/\n",
            "./variables/variables.index\n",
            "./variables/variables.data-00000-of-00001\n",
            "./saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHd9Rx-9ate5",
        "outputId": "07f678dd-c826-4e88-ffff-24b5bd1dd094"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('model/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUCCxYOxbOly",
        "outputId": "4c68587a-a83f-46ce-de97-fec02e45412f"
      },
      "source": [
        "!curl https://gsoc-tf.web.app/tokenizer.pkl -o tokenizer.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1489k  100 1489k    0     0   848k      0  0:00:01  0:00:01 --:--:--  848k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797Slmh0bPcC"
      },
      "source": [
        "import pickle\n",
        "with open('tokenizer.pkl', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRM_l_7vbbwn"
      },
      "source": [
        "example = \"mwanaume\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYNghRbEbYgQ",
        "outputId": "78332fd2-81ee-4947-9433-efb33653ae0f"
      },
      "source": [
        "model(tokenizer.texts_to_sequences([example]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
              "array([ 0.62907344,  0.2276254 ,  0.22085622, -0.46895516,  0.27026492,\n",
              "        0.2784383 ,  0.54466283,  0.21442215,  0.12079044,  0.94317925,\n",
              "       -0.34540728, -0.01303885,  0.20965706,  0.23807919,  0.0609422 ,\n",
              "        0.03674065,  0.21173401, -0.47123212,  0.4488169 ,  0.10567676,\n",
              "       -0.65623206,  0.17985752, -0.03540061,  0.3520905 , -0.3233151 ,\n",
              "       -0.24789533, -0.4004243 , -0.07531579, -0.07195444,  0.410435  ,\n",
              "        0.3338795 ,  0.25405818, -0.8489223 ,  0.29918787, -1.1747959 ,\n",
              "        0.47070527, -1.0429802 , -0.87005335,  0.696955  , -1.1065627 ,\n",
              "        0.33444297,  0.53932905,  0.48503667, -0.3742581 ,  0.9630083 ,\n",
              "        0.40159884, -0.8021837 , -0.07805784, -0.4203436 , -0.8308751 ,\n",
              "        0.09017416, -0.45730403, -0.37233385,  0.07526768, -0.2897628 ,\n",
              "       -0.62796044,  0.9930027 , -0.5539022 ,  0.09428282, -0.31144488,\n",
              "       -0.49341264, -1.4873661 , -0.36284766, -0.21989343, -0.23004624,\n",
              "       -0.35593426,  0.22962202, -0.49424598, -0.05505382,  0.0484505 ,\n",
              "        0.33905244,  1.031383  ,  0.40843973,  0.31001577, -0.08781452,\n",
              "        0.29246488, -0.01990204, -0.04235025,  0.2321048 , -0.15986289,\n",
              "        0.09421588,  0.09512472,  0.46023688, -0.51819324,  0.92723   ,\n",
              "       -0.9679772 ,  0.18399343,  0.4569036 , -0.19874923,  0.604271  ,\n",
              "       -0.05655799,  0.64112884, -0.23620509, -0.7708815 ,  0.05621384,\n",
              "       -0.27981377,  0.0535732 , -0.10906232,  0.1801354 , -0.57208246],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3FotigucMqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}